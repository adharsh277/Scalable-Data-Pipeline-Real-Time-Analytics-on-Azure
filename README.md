# Scalable Data Pipeline & Real-Time Analytics on Azure  

![Azure](https://img.shields.io/badge/Azure-Cloud-blue?logo=microsoft-azure)
![Databricks](https://img.shields.io/badge/Databricks-ETL-red?logo=databricks)
![Synapse](https://img.shields.io/badge/Azure-Synapse_SQL-lightblue?logo=azure-synapse-analytics)
![PowerBI](https://img.shields.io/badge/Power%20BI-Visualization-yellow?logo=power-bi)
![DataFactory](https://img.shields.io/badge/Azure-Data%20Factory-lightblue?logo=azure-data-factory)
![GitHub](https://img.shields.io/badge/GitHub-Version%20Control-black?logo=github)
![CI/CD](https://img.shields.io/badge/CI/CD-Automation-green?logo=githubactions)
![Python](https://img.shields.io/badge/PySpark-Transformations-orange?logo=apache-spark)
![DevOps](https://img.shields.io/badge/DevOps-Practices-informational?logo=dev.to)

---

## ğŸ“Œ Project Overview  

This project demonstrates an **enterprise-grade data engineering and analytics platform** built on **Azure Cloud**.  

It ingests raw CRM data, transforms it into curated datasets, loads into a **Synapse Data Warehouse**, and visualizes insights in **Power BI**. The project is designed to be **scalable, modular, and production-ready**, reflecting real-world Data & AI solutions.  

---

## ğŸ§° Tech Stack  

| Layer               | Tools / Tech Used                                         |
|----------------------|-----------------------------------------------------------|
| **Ingestion**        | Azure Data Factory (pipelines, triggers)                 |
| **Data Lake**        | Azure Data Lake Storage (Raw, Curated Zones)             |
| **Processing**       | Azure Databricks, PySpark (ETL & transformations)        |
| **Data Warehouse**   | Azure Synapse Analytics (SQL Pools, stored procedures)   |
| **Visualization**    | Power BI (Direct Query & Import modes)                   |
| **Orchestration**    | ADF pipelines & triggers                                 |
| **Source Control**   | Git & GitHub (with commits, versioning)                  |
| **DevOps**           | CI/CD concepts, YAML automation, Git workflows           |
| **Programming**      | Python (PySpark), SQL                                    |

---

## ğŸš€ Features  

- **Automated Data Ingestion** from CRM into Azure Data Lake (Raw Zone).  
- **Transformation Pipelines** in Databricks:  
  - Cleaning & handling null values  
  - Normalizing customer attributes  
  - Splitting `dob` into `day`, `month`, `year`  
  - Joining datasets for analytics  
- **Curated Zone Loading** into Synapse SQL tables.  
- **Analytics-Ready Warehouse** for BI dashboards.  
- **Power BI Dashboards** with:  
  - ğŸ“ˆ Customer Lifetime Value (CLV)  
  - ğŸ” Retention & Churn Trends
 
## Architecture Diagram
![Architecture Diagram ](assets/arc_diagram.png)
 

## ğŸ—ï¸ Project Structure  

``bash
crm-data-platform/
â”œâ”€â”€ data_factory/          # ADF pipeline JSONs
â”œâ”€â”€ databricks/            # PySpark notebooks (ETL transformations)
â”‚   â”œâ”€â”€ transform.py
â”‚   â””â”€â”€ notebooks.ipynb
â”œâ”€â”€ synapsanalytics/       # SQL scripts & schemas
â”‚   â”œâ”€â”€ Transactions.sql
â”‚   â””â”€â”€ metrics.sql
â”œâ”€â”€ powerbi/               # Power BI dashboards (.pbix)
â”œâ”€â”€ diagrams/              # Architecture diagrams (draw.io, PNGs)
â”œâ”€â”€ README.md              # Documentation
â””â”€â”€ .gitignore


##ğŸ“¸ Screenshots
## ğŸ“¸ Screenshots

## ğŸ”¥ Databricks

![Databricks Screenshot 1](assets/Screenshot%20(926).png)
![Databricks Screenshot 2](assets/Screenshot%20(927).png)
![Databricks Screenshot 3](assets/Screenshot%20(933).png)

## ğŸ“Š Power BI Report

![Power BI Report](assets/Order%20&%20Product%20Trends%20Report_page-0001.jpg)

## âš™ï¸ How to Run the Project
1ï¸âƒ£ Clone the Repository

git clone https://github.com/adharsh277/Scalable-Data-Pipeline-Real-Time-Analytics-on-Azure.git
cd Scalable-Data-Pipeline-Real-Time-Analytics-on-Azure
## 2ï¸âƒ£ Set up Azure Resources
Create Azure Data Lake Storage Gen2 (with Raw, Curated containers).

Deploy Azure Data Factory (import pipeline JSONs).

Set up Azure Databricks Workspace.

Provision Azure Synapse SQL Pool.

Connect Power BI to Synapse.

## 3ï¸âƒ£ Run ETL Pipelines
In ADF, trigger Ingestion pipeline â†’ loads raw CRM files to Data Lake.

ADF triggers Databricks notebooks â†’ PySpark jobs clean & transform.

Data is loaded to Synapse tables.

4ï¸âƒ£ Visualize in Power BI
Open .pbix files from powerbi/.

Connect to Synapse SQL with either Direct Query or Import mode.

Explore dashboards & insights.

ğŸ” Example PySpark Transformation (Databricks)
python
Copy code
from pyspark.sql.functions import col, split

# Load CRM raw dataset
df = spark.read.option("header", True).csv("abfss://raw@datalake.dfs.core.windows.net/crm/customers.csv")

# Clean data (drop nulls)
df = df.na.drop()

# Split DOB into separate fields
df = df.withColumn("dob_day", split(col("dob"), "-")[2]) \
       .withColumn("dob_month", split(col("dob"), "-")[1]) \
       .withColumn("dob_year", split(col("dob"), "-")[0])

# Write to curated zone
df.write.mode("overwrite").parquet("abfss://curated@datalake.dfs.core.windows.net/crm/customers_cleaned")
ğŸ“Š Example SQL (Synapse Analytics)
sql
Copy code
-- Transactions Table
CREATE TABLE dbo.Transactions (
    TransactionID INT PRIMARY KEY,
    CustomerID INT,
    Amount DECIMAL(10,2),
    TransactionDate DATE
);

-- Example Metric: Customer Lifetime Value
SELECT 
    CustomerID,
    SUM(Amount) AS LifetimeValue
FROM dbo.Transactions
GROUP BY CustomerID;
ğŸ“ˆ Power BI Dashboard Highlights
CLV Analysis â€“ Identify top customers by spend.

Churn Analysis â€“ Customers at risk based on transaction inactivity.

Regional Insights â€“ Sales by region, product categories.

Sales Funnel Conversion â€“ Stage-wise customer journey visualization.

ğŸ™Œ Learnings
Building end-to-end Azure Data Platforms.

Using PySpark for scalable transformations.

Designing star-schema models in Synapse.

Orchestrating pipelines with ADF.

Delivering business-ready insights in Power BI.

Applying DevOps practices in Data & AI.





##ğŸ™ Acknowledgments
Thanks to Microsoft Azure, Databricks, and open-source PySpark libraries for enabling enterprise data solutions.

pgsql
Copy code

  - ğŸŒ Regional Behavior Analysis  
  - ğŸ“Š Sales Funnel Conversion  
- **Scalable & Modular** structure for enterprise adoption.  
